<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>SkyNet Biometric Dashboard</title>
<meta name="viewport" content="width=device-width,initial-scale=1.0">

<!-- Astro Font -->
<link href="https://fonts.googleapis.com/css2?family=Audiowide&display=swap" rel="stylesheet"/>

<!-- MathJax -->
<script>
window.MathJax = {
  tex: { inlineMath: [["\\(","\\)"],["$", "$"]] },
  svg: { fontCache: "global" }
};
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>

<!-- Chart.js (unchanged UI) -->
<script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>

<!-- Face API (YOUR PATHS) -->
<script src="https://raw.githubusercontent.com/MomarMbergan/Vitalsjs/main/face-api.min.js"></script>
<script src="https://raw.githubusercontent.com/MomarMbergan/Vitalsjs/main/face-api.js"></script>
<script src="https://raw.githubusercontent.com/MomarMbergan/Vitalsjs/main/face-api.js.map"></script>

<style>
  body{
    margin:0;
    background:#000;
    color:#6cf;
    font-family:'Audiowide', sans-serif;
  }

container{
    width:100vw; height:100vh;
    display:flex; flex-direction:column;
    align-items:center; justify-content:flex-start;
  }
  video{
    width:320px; height:auto;
    border:2px solid #0af;
    border-radius:12px;
    margin-top:10px;
  }
  canvas{
    position:absolute; left:0; top:0;
    pointer-events:none;
  }

metrics{
    margin-top:10px;
    width:90%;
    color:#8cf;
    font-size:14px;
    text-shadow:0 0 8px #0af;
  }

  .eq{
    margin-top:6px;
    padding:6px;
    background:rgba(0,60,120,0.18);
    border-radius:12px;
    border:1px solid rgba(0,140,255,0.4);
  }
</style>

</head>
<body>
<div id="container">

  <!-- Front Camera -->
  <video id="camFront" autoplay muted playsinline></video>
  <canvas id="frontOverlay" width="320" height="240"></canvas>

  <!-- Rear Camera -->
  <video id="camRear" autoplay muted playsinline></video>
  <canvas id="rearOverlay" width="320" height="240"></canvas>

  <!-- HUD Metrics (UI unchanged) -->
  <div id="metrics">
    <div>HR Front: <span id="hrFront">0</span> bpm</div>
    <div>HR Rear: <span id="hrRear">0</span> bpm</div>
    <div>PPG: <span id="ppgValue">0</span></div>
    <div>SpO₂: <span id="spo2Value">0</span>%</div>

    <!-- NEW METRIC BLOCK (below SpO2), divided by live PPG -->
    <div id="equationsBlock" class="eq">
      <strong>Eye Metrics (normalized / PPG):</strong>

      <div id="eqGamma">\( \gamma = \frac{I{max}}{I{min}} \div PPG \)</div>
      <div id="eqP">\( P = \frac{TP}{TP+FP} \div PPG \)</div>
      <div id="eqDepth">\( \sqrt{D^2 - d^2} \div PPG \)</div>
      <div id="eqHRN">\( \text{NormHR} = \frac{Metric}{HR} \div PPG \)</div>
      <div id="eqLens">\( \frac{1}{f} = \frac{1}{u} + \frac{1}{v} \div PPG \)</div>
      <div id="eqInvSq">\( L \propto \frac{1}{d^2} \div PPG \)</div>
    </div>
  </div>

</div>

<script>
/* ===========================================================
   LOAD FACE-API MODELS
=========================================================== */
async function loadModels(){
  await faceapi.nets.tinyFaceDetector.loadFromUri('./');
  await faceapi.nets.faceLandmark68TinyNet.loadFromUri('./');
}
loadModels();

/* ===========================================================
   CAMERA START (front + rear)
=========================================================== */
async function startCam(id, facingMode){
  const stream = await navigator.mediaDevices.getUserMedia({
    video:{ facingMode:facingMode, width:640, height:480 }
  });

  const vid = document.getElementById(id);
  vid.srcObject = stream;
}

startCam("camFront","user");
startCam("camRear","environment");

/* ===========================================================
   SNAPSHOT + BICUBIC SCALE 512×384
=========================================================== */
function getEyeCrop(video){
  const tmp = document.createElement("canvas");
  tmp.width = 512;
  tmp.height = 384;

  const ctx = tmp.getContext("2d");
  ctx.imageSmoothingEnabled = true;
  ctx.imageSmoothingQuality = "high";

  ctx.drawImage(video, 0, 0, 512, 384);
  return tmp;
}

/* ===========================================================
   MATH — compute eye metrics
=========================================================== */
function computeGamma(imgData){
  let min = 255, max = 0;
  const d = imgData.data;
  for(let i=0;i<d.length;i+=4){
    const v = d[i];
    if (v<min) min=v;
    if (v>max) max=v;
  }
  return max/min;
}

function computePrecision(tp, fp){
  return tp / (tp + fp + 1e-9);
}

function computeDepth(D,d){
  return Math.sqrt(Math.max(DD - dd,0));
}

function thinLens(u,v){
  return 1/(1/u + 1/v);
}

function invSq(d){
  return 1/(d*d + 1e-9);
}

/* ===========================================================
   UPDATE EQUATION HTML (renders with MathJax automatically)
=========================================================== */
function updateEquations(gamma, prec, depth, hr, ppg){
  gamma /= (ppg||1);
  prec /= (ppg||1);
  depth /= (ppg||1);

  const lens = (1/30).toFixed(4); // placeholder
  const inv = (1/5000).toFixed(4);

  document.getElementById("eqGamma").innerHTML = \( \\gamma = ${gamma.toFixed(3)} \);
  document.getElementById("eqP").innerHTML     = \( P = ${prec.toFixed(3)} \);
  document.getElementById("eqDepth").innerHTML = \( ${depth.toFixed(3)} \);
  document.getElementById("eqHRN").innerHTML   = \( \\frac{Metric}{${hr}} = ${(1/(hr||1)).toFixed(3)} \);
  document.getElementById("eqLens").innerHTML  = \( f = ${lens} \);
  document.getElementById("eqInvSq").innerHTML = \( L \\propto ${inv} \);

  MathJax.typeset();
}

/* ===========================================================
   MAIN LOOP — detect eyes on both cameras
=========================================================== */
async function eyeLoop(){
  const vids = [
    { vid:camFront, overlay:frontOverlay, hr:hrFront },
    { vid:camRear,  overlay:rearOverlay,  hr:hrRear  }
  ];

  for(const v of vids){
    if(v.vid.readyState >= 2){
      const det = await faceapi.detectSingleFace(
        v.vid,
        new faceapi.TinyFaceDetectorOptions()
      ).withFaceLandmarks(true);

      const ctx = v.overlay.getContext("2d");
      ctx.clearRect(0,0,320,240);

      if(det){
        const pts = det.landmarks.getLeftEye();

        ctx.strokeStyle="#0af";
        ctx.lineWidth=2;
        ctx.beginPath();
        pts.forEach((p,i)=>{
          if(i===0) ctx.moveTo(p.x,p.y);
          else ctx.lineTo(p.x,p.y);
        });
        ctx.closePath();
        ctx.stroke();

        const crop = getEyeCrop(v.vid);
        const imgData = crop.getContext("2d").getImageData(0,0,512,384);

        // Dummy TP/FP for now
        const P = computePrecision(120,3);
        const gamma = computeGamma(imgData);
        const depth = computeDepth(12,4);

        const hrVal = Number(v.hr.textContent)||60;
        const ppgVal = Number(ppgValue.textContent)||1;

        updateEquations(gamma, P, depth, hrVal, ppgVal);
      }
    }
  }

  requestAnimationFrame(eyeLoop);
}
eyeLoop();

</script>

</body>
</html>
